# Evolution of Todo Constitution

<!--
Sync Impact Report:
Version: 1.0.0 → 1.3.0 (MINOR: Added Development Standards + Clarified Priority Terminology)

Changes:
- Added "Development Standards" section with 6 subsections
- Enhanced Phase I with Definition of Done (MVP + Production-Ready)
- Renamed "Task Priority Levels" to "Feature Requirements" to clarify implementation order vs user-facing task priority
- Added clarification note distinguishing feature implementation priority from task priority field
- Specified branch name for Phase I: 001-cli-todo-app

New Sections Added:
1. Testing Requirements (TDD, coverage, structure)
2. Version Control & Branching (naming, commits)
3. Environment Setup (venv, .env, dependencies)
4. Approval Process (spec/plan/task approval workflow)
5. Code Documentation (docstring standards)
6. Logging Standards (library, format, levels)

Modified Sections:
- Phase I: Added MVP and Production-Ready Definition of Done
- Phase I: Renamed "Task Priority Levels" to "Feature Requirements" with clarification note
- Phase I: Added branch name specification

Templates Requiring Updates:
✅ No template changes needed - all additions support existing workflows

Rationale for MINOR version bump:
- New Development Standards section adds material guidance
- Non-breaking: all existing principles remain unchanged
- Enables immediate Phase I execution with clear criteria

Follow-up TODOs: None
-->

## Overview

This constitution governs the development of the "Evolution of Todo" project for Hackathon II. It enforces Spec-Driven Development (SDD) using Claude Code and Spec-Kit Plus, shifting the role from syntax writer to system architect. The project evolves a Todo app from a simple CLI to a cloud-native AI system, incorporating Reusable Intelligence through skills and subagents.

## Core Principles

### I. Spec-Driven Development (SDD)

All features MUST start with a Markdown spec. Refine specs iteratively until Claude Code generates correct implementations. No manual coding is allowed—only spec refinement and prompt engineering.

**Rationale**: SDD ensures requirements are clear, testable, and auditable before implementation. It eliminates ambiguity and provides a documented decision trail for judges. Manual coding violates the hackathon's agentic development philosophy.

**Requirements**:
- Every feature MUST have a spec in `/specs/[###-feature-name]/spec.md`
- Specs MUST be refined through Claude Code iterations before implementation
- All spec iterations MUST be tracked in `/specs/[###-feature-name]/history/`
- No code may be written manually—all code MUST be generated by Claude Code

### II. Agentic Dev Stack Workflow

Follow the strict workflow: Write spec → Generate plan → Break into tasks → Implement via Claude Code. Use Spec-Kit Plus for spec management (e.g., init, generate plan, validate).

**Rationale**: This workflow enforces systematic development and leverages Claude Code's strengths. It ensures planning precedes implementation and maintains traceability from requirements to code.

**Requirements**:
- ALL features MUST follow: `/sp.specify` → `/sp.plan` → `/sp.tasks` → `/sp.implement`
- Plans MUST be approved before task generation
- Tasks MUST be approved before implementation
- Document all Claude sessions and prompts in `CLAUDE.md`

### III. Reusable Intelligence

Design modular skills and subagents using the P+Q+P framework (Problem + Query + Plan). Create reusable components like "TaskManagerSkill" for CRUD operations to maximize bonus points.

**Rationale**: Reusable Intelligence demonstrates mastery of agentic patterns and earns +200 bonus points. Modular skills improve maintainability and enable composition of complex behaviors.

**Requirements**:
- Skills MUST follow the P+Q+P framework
- Each skill MUST have clear problem definition, query interface, and execution plan
- Skills MUST be independently testable and reusable across features
- Document skill architecture in `/specs/skills/` for bonus point validation

### IV. Clean Code and Structure

Adhere to Python best practices (PEP8), modular design, and proper project structure. Use UV for dependency management.

**Rationale**: Clean code ensures maintainability, readability, and professional quality expected in hackathon submissions. Proper structure supports scaling from CLI to cloud-native architecture.

**Requirements**:
- ALL Python code MUST conform to PEP8 standards
- MUST use UV for dependency management (Python 3.13+)
- Project structure MUST follow monorepo pattern: `/src/`, `/specs/`, `/tests/`, `/frontend/`, `/backend/` (as phases evolve)
- MUST maintain separation of concerns: models, services, CLI, API layers
- Configuration MUST use environment variables (`.env` files)

### V. No Manual Interventions

Code MUST be generated by Claude Code. Document all Claude sessions, prompts, and iterations in `CLAUDE.md` for judging transparency.

**Rationale**: Manual coding disqualifies the submission per hackathon rules. Complete documentation proves authentic agentic development and helps judges evaluate prompt engineering skill.

**Requirements**:
- Zero manual code writing permitted
- EVERY Claude Code session MUST be documented in `CLAUDE.md`
- MUST record: prompt text, generated code, iteration count, refinements made
- Document failures and how specs were adjusted to achieve success
- Violations invalidate the submission

### VI. Bonus Alignment

Incorporate features that earn bonus points: Reusable Intelligence (+200), Cloud-Native Blueprints (+200), Multi-language Support (Urdu chatbot, +100), Voice Commands (+200).

**Rationale**: Bonus features differentiate submissions and demonstrate advanced capabilities. Strategic alignment maximizes scoring potential (up to +700 points).

**Requirements**:
- Plan bonus features explicitly in spec and plan documents
- Reusable Intelligence: document skills in `/specs/skills/`
- Cloud-Native: implement in Phase IV/V with Docker, K8s, Kafka, Dapr
- Multi-language: add Urdu support in Phase III chatbot
- Voice Commands: integrate voice interface in Phase III or later
- MUST document bonus feature implementation for judge validation

### VII. Ethical and Compliant Development

Ensure user data isolation (e.g., via authentication in later phases), scalability, and alignment with cloud-native principles.

**Rationale**: Professional applications require security, privacy, and scalability. Demonstrating these principles shows production-readiness and responsible engineering.

**Requirements**:
- User data MUST be isolated per user (implement auth in Phase II+)
- MUST follow principle of least privilege for access control
- Sensitive data (passwords, tokens) MUST use secure storage (env vars, secrets managers)
- MUST implement proper error handling without leaking sensitive information
- Design MUST support horizontal scaling (stateless services in cloud phases)

## Development Standards

### Testing Requirements
- **TDD Mandatory**: Write tests BEFORE implementation for all features
- **Phase I Coverage**: Minimum 70% for MVP, 80% for production-ready
- **Test Structure**: Mirror src/ in tests/ (e.g., `src/models/task.py` → `tests/unit/models/test_task.py`)
- **Test Categories**: Unit tests in `tests/unit/`, integration tests in `tests/integration/`
- **Test Execution**: Run `pytest` before marking any task complete

### Version Control & Branching
- **Branch Naming**: `###-feature-name` format (e.g., `001-cli-todo-app`, `002-task-persistence`)
- **Feature Numbering**: Start at 001, increment sequentially per feature
- **Commit Frequency**: Commit after each completed task from tasks.md
- **Commit Format**: `feat(scope): description` for features, `fix(scope): description` for bugs
- **Example**: `git checkout -b 001-cli-todo-app` then `git commit -m "feat(cli): add task creation menu"`

### Environment Setup
- **Virtual Environment**: Use `uv venv` to create, `source .venv/bin/activate` to activate
- **Environment Variables**: Create `.env` file with `LOG_LEVEL=DEBUG` and `APP_NAME=evolution-todo`
- **Dependencies**: Manage via `uv add <package>` and `uv pip compile` for lock files

### Approval Process
- **Spec Approval**: User reviews and confirms spec.md in chat before running `/sp.plan`
- **Plan Approval**: User reviews and confirms plan.md in chat before running `/sp.tasks`
- **Task Approval**: User reviews and confirms tasks.md in chat before running `/sp.implement`
- **Mechanism**: Claude Code will pause and request explicit approval at each transition

### Code Documentation
- **Docstrings**: All public functions MUST have Google-style docstrings
- **Required Sections**: Description, Args, Returns, Raises (if applicable)
- **Example**:
  ```python
  def add_task(title: str, description: str) -> dict:
      """Add a new task to the task list.

      Args:
          title: Task title (required, non-empty)
          description: Task description (optional)

      Returns:
          dict: Created task with id, title, description, complete fields

      Raises:
          ValueError: If title is empty
      """
  ```

### Logging Standards
- **Library**: Python standard `logging` module
- **Format**: `%(asctime)s - %(name)s - %(levelname)s - %(message)s`
- **Levels**: DEBUG for development, INFO for production, ERROR for failures
- **Requirement**: Log all CRUD operations at INFO level

## Phase-Specific Guidelines

### Phase I: In-Memory Python Console App

**Scope**: Implement Basic Level features (Add Task, Delete Task, Update Task, View Task List, Mark as Complete) in a CLI app with in-memory storage.

**Data Structure**: Use a list of dictionaries (e.g., `{'id': int, 'title': str, 'description': str, 'complete': bool}`).

**Interface**: Menu-driven CLI with user prompts.

**Technology**: Python 3.13+, UV, Claude Code, Spec-Kit Plus.

**Deliverables**:
- Specs in `/specs/` (with history tracking)
- Source in `/src/`
- `CLAUDE.md` with all sessions documented
- `README.md` with setup and usage instructions

**Definition of Done (MVP)**:
- ✅ All 5 basic features implemented and working (Add, Delete, Update, View, Mark Complete)
- ✅ In-memory storage functional with proper data structure
- ✅ Menu-driven CLI with user prompts and error handling
- ✅ 70%+ test coverage (verified with `pytest --cov`)
- ✅ All code PEP8 compliant (verified with `ruff check`)
- ✅ README.md with setup and usage instructions
- ✅ CLAUDE.md with all sessions documented
- ✅ All tests passing (`pytest` exits with 0)

**Definition of Done (Production-Ready)**:
- All MVP criteria PLUS:
- ✅ 80%+ test coverage
- ✅ Input validation for all edge cases
- ✅ Comprehensive error handling with user-friendly messages
- ✅ All functions have Google-style docstrings
- ✅ Logging implemented for all CRUD operations

**Phase I Feature Requirements** (implementation order):
- **High (Must Have for MVP)**: Add Task, View Task List, Mark Complete
- **Medium (Should Have)**: Update Task, Delete Task
- **Normal (Nice to Have)**: Input validation enhancements, colored CLI output

**Note**: The High/Medium/Low terminology above refers to which features must be implemented for MVP. This is separate from the task priority field (High/Medium/Low) that users set when adding tasks to their todo list.

**Branch**: `001-cli-todo-app`

### Phase II: Full-Stack Web Application

**Scope**: Convert CLI to web app with REST API (backend) and React frontend. Add persistent storage (Neon PostgreSQL) and authentication (Better Auth + JWT).

**Technology**: FastAPI or Flask (backend), React + TailwindCSS (frontend), Neon PostgreSQL.

**Structure**: Expand to `/backend/` and `/frontend/` directories.

**Constitution Compliance**:
- Maintain SDD workflow with separate specs for frontend and backend features
- Implement authentication per Principle VII (user data isolation)
- Document API contracts in `/specs/[feature]/contracts/`

### Phase III: AI-Powered Chatbot

**Scope**: Add conversational AI interface using OpenAI Agents SDK or MCP SDK. Support natural language task management. Include Urdu support (+100 bonus).

**Technology**: OpenAI Agents SDK, MCP SDK, LangChain/LlamaIndex (optional).

**Constitution Compliance**:
- Design chatbot as Reusable Intelligence component (Principle III)
- Multi-language support earns bonus points (Principle VI)
- Consider voice command integration (+200 bonus)

### Phase IV: Local Kubernetes Deployment

**Scope**: Containerize with Docker, deploy to Minikube with multi-pod architecture, add Kafka for event streaming.

**Technology**: Docker, Minikube, Kafka, Dapr (sidecar pattern).

**Constitution Compliance**:
- Cloud-Native Blueprints (+200 bonus, Principle VI)
- Demonstrate scalability (Principle VII)
- Document infrastructure as code in `/specs/infrastructure/`

### Phase V: Advanced Cloud & Orchestration

**Scope**: Kubernetes orchestration, Dapr integration, advanced AI features, comprehensive observability.

**Technology**: Kubernetes, Dapr, Prometheus, Grafana, OpenTelemetry.

**Constitution Compliance**:
- Complete cloud-native transformation
- Full observability and monitoring (aligns with professional quality)
- Demonstrate all bonus features if implemented

## Governance

This constitution supersedes all other practices. Amendments require:
1. Documented rationale for change
2. Approval from project lead or team consensus
3. Migration plan for impacted specs and code
4. Version increment per semantic versioning

All pull requests and reviews MUST verify compliance with this constitution. Complexity MUST be justified (reference Principle IV and plan-template.md Complexity Tracking section). Any code generated by Claude Code MUST be traced to its originating spec.

Use `CLAUDE.md` for runtime development guidance and session tracking.

**Version**: 1.3.0 | **Ratified**: 2025-12-17 | **Last Amended**: 2025-12-17
